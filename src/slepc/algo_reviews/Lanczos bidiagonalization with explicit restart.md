## Введение ##
Метод Ланцоша [1950] стал одним из самых успешных методов для приближённого вычисления нескольких собственных значений вещественной симметричной (или комплексной эрмитовой) матрицы. Изначально метод не привлёк особого внимания, так как его рассматривали как метод для приведения матрицы к тридиагональной форме, что лучше выполнялось методами Гивенса и Хаусхолдера. Чтобы конкурировать по точности, метод Ланцоша должен был быть дополнен явной ортогонализацией вычисленных векторов, которые при точной арифметике автоматически были бы ортогональными. Спустя много лет возобновление интереса к методу Ланцоша вызвала работа Пейджа, которая привела к серии важных вкладов со стороны многих авторов, что способствовало лучшему пониманию метода и расширению его применимости. Некоторые из этих вкладов описаны в этом отчёте (раздел 2), чтобы мотивировать рассмотрение конкретных вариантов, реализованных в slepc (раздел 3).

Метод Ланцоша связан с методом Арнольди в том смысле, что Ланцош можно рассматривать как частный случай метода Арнольди, когда матрица симметрична. По этой причине у обоих методов есть общие аспекты. Для подробного описания метода Арнольди см. технический отчёт slepc STR-4, “Arnoldi Methods in slepc”.

Этот отчёт не включает материалы о несимметричной версии метода Ланцоша. Собственные значения, основанные на этом методе, могут быть добавлены в будущие версии slepc.

## Описание алгоритма ##
Этот раздел предоставляет обзор метода Ланцоша и некоторых его вариаций, включая методы для предотвращения потери ортогональности.
Метод Ланцоша может быть выведен с разных точек зрения. Один из таких подходов заключается в приведении симметричной матрицы <i>A</i> порядка <i>n × n</i> к тридиагональной форме с помощью трёхчленной рекуррентной формулы. Задав начальный вектор <i>v<sub>1</sub></i> с единичной нормой и положив <i>β<sub>1</sub> = 0</i>, применяют следующую рекуррентную формулу:

<p align="center">β<sub>j+1</sub>v<sub>j+1</sub> = Av<sub>j</sub> − α<sub>j</sub> v<sub>j</sub> − β<sub>j</sub> v<sub>j−1</sub>(1),</p>

где <i>α<sub>j</sub> = v<sub>j</sub><sup>*</sup> A v<sub>j</sub></i> и <i>β<sub>j+1</sub> = v<sub>j+1</sub><sup>*</sup> A v<sub>j</sub></i>, что порождает ортонормированный набор векторов Ланцоша <i>v<sub>j</sub></i> и тридиагональную матрицу, определённую как

<table border="1" cellpadding="5" cellspacing="0">
  <tr>
    <td>α<sub>1</sub></td>
    <td>β<sub>2</sub></td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>β<sub>2</sub></td>
    <td>α<sub>2</sub></td>
    <td>β<sub>3</sub></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td></td>
    <td>β<sub>3</sub></td>
    <td>α<sub>3</sub></td>
    <td>⋱</td>
    <td></td>
  </tr>
  <tr>
    <td></td>
    <td></td>
    <td>⋱</td>
    <td>⋱</td>
    <td>β<sub>n</sub></td>
  </tr>
  <tr>
    <td></td>
    <td></td>
    <td></td>
    <td>β<sub>n</sub></td>
    <td>α<sub>n</sub></td>
  </tr>
</table>


Можно показать, что вектор <i>v<sub>n+1</sub></i> равен нулю, и выполняется следующее соотношение:
<p align="center">A V − V T = 0 (3),</p>

где <i>V = [v<sub>1</sub>, v<sub>2</sub>, . . . , v<sub>n</sub>]</i>. То есть рекурсия Ланцоша вычисляет тридиагональную матрицу, которая ортогонально подобна <i>A</i>.

При описании алгоритма вычисления рекурсии Ланцоша можно учитывать два замечания. Первое заключается в том, что <i>β<sub>j+1</sub></i> можно вычислить как <i>‖Av<sub>j</sub> − α<sub>j</sub> v<sub>j</sub> − β<sub>j</sub> v<sub>j−1</sub>‖<sub>2</sub></i>, поскольку <i>v<sub>j+1</sub></i> имеет единичную норму. Численный анализ, проведенный Пейджем [1972], показывает, что этот альтернативный подход улучшает численную устойчивость при реализации рекурсии в арифметике с конечной точностью. 

Второе замечание заключается в том, что <i>α<sub>j</sub></i> можно вычислить как <i>v<sub>j</sub><sup>*</sup>(Av<sub>j</sub> − β<sub>j</sub> v<sub>j−1</sub>)</i>, поскольку <i>v<sub>j</sub></i> и <i>v<sub>j−1</sub></i> ортогональны по конструкции. Этот альтернативный подход также поддерживается Пейджем [1980]. Учитывая эти замечания, основной алгоритм Ланцоша можно записать как в Алгоритме 1.

### Алгоритм 1 (Базовый алгоритм Ланцоша — вид рекурсии)

1. Выберите вектор единичной нормы <i>v<sub>1</sub></i>.
2. Установите <i>β<sub>1</sub> = 0</i>.
3. Для <i>j = 1, 2, . . .</i>:
   - <i>u<sub>j+1</sub> = Av<sub>j</sub> − β<sub>j</sub> v<sub>j−1</sub></i>
   - <i>α<sub>j</sub> = v<sub>j</sub><sup>*</sup> u<sub>j+1</sub></i>
   - <i>u<sub>j+1</sub> = u<sub>j+1</sub> − α<sub>j</sub> v<sub>j</sub></i>
   - <i>β<sub>j+1</sub> = ‖u<sub>j+1</sub>‖<sub>2</sub></i>
   - Если <i>β<sub>j+1</sub> = 0</i>, остановитесь.
   - <i>v<sub>j+1</sub> = u<sub>j+1</sub>/β<sub>j+1</sub></i>.
4. Конец.

Конечно, алгоритм Ланцоша наиболее полезен, когда не вычисляются все <i>n</i> векторы, что невозможно в контексте очень больших матриц. Если выполняется только <i>m</i> шагов Ланцоша, то вместо уравнения (3) имеет место следующее соотношение:

<p align="center">A V<sub>m</sub> − V<sub>m</sub>T<sub>m</sub> = β<sub>m+1</sub> v<sub>m+1</sub> e<sub>m</sub><sup>*</sup>,</p> (4)

где <i>T<sub>m</sub></i> — это ведущая подматрица размера <i>m × m</i> матрицы <i>T</i>, а <i>V<sub>m</sub> = [v<sub>1</sub>, v<sub>2</sub>, . . . , v<sub>m</sub>]</i>. Уравнение (4) описывает остаток <i>m</i>-шаговой факторизации Арнольди. То есть процесс Ланцоша также можно рассматривать как вычисление ортогонального проекции матрицы <i>A</i> на криловское подпространство <i>K<sub>m</sub>(A, v<sub>1</sub>)</i>. С этой точки зрения метод Ланцоша эквивалентен методу Арнольди, см. Алгоритм 2.

### Алгоритм 2 (Базовый алгоритм Ланцоша — вид проекции)

**Входные данные:** Матрица <i>A</i>, число шагов <i>m</i> и начальный вектор <i>v<sub>1</sub></i> нормы 1.  
**Выходные данные:** (<i>V<sub>m</sub>, T<sub>m</sub>, v<sub>m+1</sub>, β<sub>m+1</sub></i>) так, что 

<p align="center">A V<sub>m</sub> − V<sub>m</sub>T<sub>m</sub> = β<sub>m+1</sub> v<sub>m+1</sub> e<sub>m</sub><sup>*</sup></p>

Для <i>j = 1, 2, . . . , m</i>:
- <i>u<sub>j+1</sub> = A v<sub>j</sub></i>
- Ортогонализируйте <i>u<sub>j+1</sub></i> относительно <i>V<sub>j</sub></i> (вычисляя <i>α<sub>j</sub></i>)
- <i>β<sub>j+1</sub> = ‖u<sub>j+1</sub>‖<sub>2</sub></i>
- Если <i>β<sub>j+1</sub> = 0</i>, остановитесь
- <i>v<sub>j+1</sub> = u<sub>j+1</sub>/β<sub>j+1</sub></i>

Конец.

В Алгоритме 2 вторая строка в цикле выполняет процесс Грама-Шмидта для ортогонализации вектора <i>u<sub>j+1</sub></i> относительно столбцов <i>V<sub>j</sub></i>, то есть векторов <i>v<sub>1</sub>, v<sub>2</sub>, . . . , v<sub>j</sub></i> (см. технический отчет SLEPc STR-1, «Рутины ортогонализации в SLEPc» для подробностей о Граме-Шмидте). В этой операции вычисляются <i>j</i> коэффициентов Фурье. В точной арифметике первые <i>j−2</i> коэффициента равны нулю, и, следовательно, соответствующие операции не нужно выполнять (ортогональность относительно первых <i>j − 2</i> векторов является автоматической). Другие два коэффициента — это <i>β<sub>j</sub></i> и <i>α<sub>j</sub></i>. Обратите внимание, что, согласно Пейджу, <i>β<sub>j</sub></i>, вычисленный в этой операции, следует отбросить, и вместо него использовать значение <i>‖u<sub>j</sub>‖<sub>2</sub></i>, вычисленное на предыдущей итерации. С точки зрения ортогонализации, Алгоритм 1 выполняет модифицированный шаг Грама-Шмидта только с векторами <i>v<sub>j−1</sub></i> и <i>v<sub>j</sub></i>, в то время как вычисление <i>α<sub>j</sub></i> как <i>v<sub>j</sub><sup>*</sup>Av<sub>j</sub></i> соответствовало бы классическому Граму-Шмидту.

В дальнейшем мы сосредоточим наше обсуждение на Алгоритме 2, поскольку ортогонализация будет ключевым аспектом устойчивых вариантов Ланцоша, которые справляются с потерей ортогональности.

Как и в случае с методом Арнольди, поскольку <i>V<sub>m</sub><sup>*</sup>v<sub>m+1</sub> = 0</i> по конструкции, то, предварительно умножив уравнение (4) на <i>V<sub>m</sub><sup>*</sup></i>, получаем:

<p align="center">V<sub>m</sub><sup>*</sup>A V<sub>m</sub> = T<sub>m</sub>(5),</p>
То есть матрица <i>T<sub>m</sub></i> представляет собой ортогональную проекцию матрицы <i>A</i> на криловское подпространство, и этот факт позволяет нам вычислять приближения Рейли-Ритца для собственных пар матрицы <i>A</i>. Пусть <i>(λ<sub>i</sub>, y<sub>i</sub>)</i> — собственная пара матрицы <i>T<sub>m</sub></i>, тогда значение Ритца <i>λ<sub>i</sub></i> и вектор Ритца <i>x<sub>i</sub> = V<sub>m</sub>y<sub>i</sub></i> могут быть приняты в качестве приближений для собственных пар матрицы <i>A</i>. Обычно лишь небольшая часть из <i>m</i> приближений является качественной. Это можно оценить с помощью нормы остатка для пары Ритца, которую довольно легко вычислить:

<p align="center">‖A x<sub>i</sub> − λ<sub>i</sub>x<sub>i</sub}‖<sub>2</sub> = ‖A V<sub>m</sub>y<sub>i</sub> − λ<sub>i</sub>V<sub>m</sub>y<sub>i</sub>‖<sub>2</sub> = ‖(AV<sub>m</sub> − V<sub>m</sub>T<sub>m</sub>)y<sub>i</sub>‖<sub>2</sub> = β<sub>m+1</sub>|e<sub>m</sub><sup>*</sup>y<sub>i</sub>|. (6)</p>

Единственное отличие от метода Арнольди заключается в том, что <i>T<sub>m</sub></i> является симметричной тридегональной матрицей, и, следовательно, существует больше возможных методов для вычисления ее собственных пар.

Алгоритм Ланцоша в конечной арифметике сталкивается с проблемами, связанными с потерей ортогональности вектора Ланцоша, что приводит к появлению спurious eigenvalues (ложных собственных значений) и множественных копий значений Ритца. Чтобы решить эти проблемы и поддерживать эффективность алгоритма, вводится концепция рестарта. 

**Основные причины использования рестарта:**

1. **Сохранение ортогональности**: При выполнении большого количества итераций алгоритма векторы Ланцоша теряют взаимную ортогональность. Рестарт позволяет начать новый процесс с ограниченным числом векторов, что помогает избежать потери ортогональности.

2. **Снижение вычислительных затрат**: Полная ортогонализация требует хранения всех векторов Ланцоша в памяти и увеличивает вычислительные затраты с увеличением числа шагов. Рестарт ограничивает количество хранимых векторов и, таким образом, снижает затраты на память и вычисления.

3. **Улучшение качества приближений**: Рестарт позволяет сосредоточиться на получении более точных приближений собственных значений, избегая проблемы с накоплением ошибок, которые могут возникнуть при долгих итерациях.

4. **Параллельные вычисления**: При реализации параллельных методов наличие большого количества векторов может привести к снижению производительности. Рестарт позволяет упростить процесс и улучшить эффективность вычислений.

Далее расмотрим вариант алгоритма с перезапуском.



## Имплементация ##
## Список литературы ##
Lanczos and the Riemannian SVD in information retrieval applications-Fierro-Jiang-2005.pdf